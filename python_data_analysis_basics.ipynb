{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIikg8cpf2ab"
      },
      "source": [
        "# 1 Intro\n",
        "\n",
        "This notebook takes you through some basic data manipulation and analysis tasks by utilizing a few popular Python data science packages. In particular, we will use the following 4 packages.\n",
        "\n",
        "1. [pandas](https://pandas.pydata.org/), a library for data processing. It mainly operates on 2D tables with columns and rows called dataframes.\n",
        "2. [yfinance](https://ranaroussi.github.io/yfinance/index.html), a library to download market data from Yahoo Finance.\n",
        "3. [matplotlib](https://matplotlib.org/), a library for plotting charts.\n",
        "4. [scikit-learn](https://scikit-learn.org/stable/index.html), a library for machine learning.\n",
        "\n",
        "The purpose of this notebook is to get you started with the basics of data processing and modeling. Refer to the \"Resources\" section in the workshop website, and you will find more learning materials to advance your Python data science skill."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Data\n",
        "\n",
        "Before we can use third party modules (i.e., packages or libraries), we need to import them. Normally, we would first need to install the modules. However, since we are running the code in Google Colab, and Google Colab has already installed many commonly used Python module for us, we can skip the installation step here.\n",
        "\n",
        "(You can use the command `!pip list` to list all packages that has been installed in Google Colab. The `!` in the command means that `pip list` is a terminal utility command rather than Python code.)"
      ],
      "metadata": {
        "id": "h14CwMAOFVf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdx_oPqNftG6"
      },
      "outputs": [],
      "source": [
        "# import the modules needed for this notebook\n",
        "# we will import sklearn later\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [yfinance](https://ranaroussi.github.io/yfinance/index.html) package can retrieve data from Yahoo Finance in many different ways. Here, we simply download a daily \"SPY\" series using its [`download()`](https://ranaroussi.github.io/yfinance/reference/api/yfinance.download.html#yfinance.download) function. The function returns a pandas dataframe.\n",
        "\n",
        "In our example, we set the `download()` function's `auto_adjust` parameter to `False` so it returns explicitly both closing price and adjusted closing price. By default, `auto_adjust=True` and the closing price is automatically/implicitly adjusted and returned as closing price.\n",
        "\n",
        "We also set the `multi_level_index` to `False` so that the columns of the returning dataframe have only one level instead of two, for example, the adjusted closing price column is `Adj Close` instead of `(Adj Close, SPY)`. This simplifies the returned dataframe and works well for our case since we only plan to download data for a single ticker SPY."
      ],
      "metadata": {
        "id": "3T5e_7mgHV-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downlad SPY time series from Yahoo Finance\n",
        "df = yf.download(\"SPY\", start=\"2023-01-01\", end=\"2024-06-30\", auto_adjust=False, multi_level_index=False)"
      ],
      "metadata": {
        "id": "wHE3AeZ3VWII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at first few rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "p92X4mAeVYph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pandas dataframe consists of an index and columns. The index of a dataframe is a series of labels that identify each row. A column is a series of values identified by a column head/name/variable. (Both index and column can have mulitple levels in more complicated cases.)"
      ],
      "metadata": {
        "id": "5WzEZp9iXmof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the Date column is not really a column but an index, in particular, DatetimeIndex\n",
        "# the columns are Adj Close, Close, High, Low, Open, Volume\n",
        "df.info()"
      ],
      "metadata": {
        "id": "6BzZcCFkXRux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the index\n",
        "df.index"
      ],
      "metadata": {
        "id": "3HXncDThX4AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display column names\n",
        "df.columns"
      ],
      "metadata": {
        "id": "76P0g6xMVg6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# descriptive statistics\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "WY1BaPspFDt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqis9sh3B1UU"
      },
      "source": [
        "`.loc` and `.iloc` are methods associated with a dataframe for indexing, slicing and filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuS1-bQQVZ2C"
      },
      "outputs": [],
      "source": [
        "# locate rows based on a condition and select only 'Adj Close' column\n",
        "df.loc[df.index<='2023-01-05', ['Adj Close']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPRT3MYkVSgw"
      },
      "outputs": [],
      "source": [
        "# locate rows and select columns using integer positions\n",
        "# :5 means from start to the fifth row (excluding the fifth row), same as 0:5\n",
        "# -1 means the last column\n",
        "df.iloc[:5, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsp0EjFTB_YB"
      },
      "source": [
        "Among all the columns, we will only use two, `Volume` and `Adj Close`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWGpb-5fkyM5"
      },
      "outputs": [],
      "source": [
        "# select only two columns, ['Adj Close', 'Volume']\n",
        "df = df[['Adj Close', 'Volume']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRShbwHcCGnK"
      },
      "source": [
        "We will use matplotlib to display adjusted closing prices over time in a line plot."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# line plot\n",
        "ax.plot(df['Adj Close'])\n",
        "\n",
        "# set the title\n",
        "ax.set_title('Daily Adjusted Closing Price of SPY (USD)')\n",
        "\n",
        "# display plot (optional in the notebook setting)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m-MK11xwK-KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Plot a line chart for SPY daily volumes in 2024."
      ],
      "metadata": {
        "id": "slzA-J2ZLpHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n"
      ],
      "metadata": {
        "id": "pl54BP7LL7fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjqkCSwCPGH"
      },
      "source": [
        "# 3 Simple Analysis\n",
        "\n",
        "The DatetimeIndex gives us more ways of extracting information from it. For example, we can extract year, month and weekday information for each date and create new dataframe columns for them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNyOTHHSWV4N"
      },
      "outputs": [],
      "source": [
        "# create year, month and weekday columns\n",
        "df['year']=df.index.year\n",
        "df['month']=df.index.month\n",
        "df['weekday']=df.index.weekday\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMeGYEqCbT-"
      },
      "source": [
        "Methods such as `.groupby` can be used for data aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-avbKmGjDnB9"
      },
      "outputs": [],
      "source": [
        "# mean adjusted closing price by year and month\n",
        "df.groupby(['year', 'month'])['Adj Close'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since the data is sorted by the DatetimeIndex, we can also retrieve the\n",
        "# end of month adjusted closing price\n",
        "df.groupby(['year', 'month'])['Adj Close'].last()"
      ],
      "metadata": {
        "id": "bz2ACG-7SDJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jztVnWcJDn-L"
      },
      "source": [
        "Let's calculate the daily returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFphBat6j0QC"
      },
      "outputs": [],
      "source": [
        "# since the data is sorted by the DatetimeIndex, shift(1) gives previous\n",
        "# trading day's adjusted closing price\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html\n",
        "df['return'] = (df['Adj Close'] / df['Adj Close'].shift(1) - 1) * 100\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot daily returns\n",
        "# create figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# line plot\n",
        "ax.plot(df['return'])\n",
        "\n",
        "# set the title\n",
        "ax.set_title('Daily Return of SPY (%)')\n",
        "\n",
        "# display plot (optional in the notebook setting)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u9X7kdAUT_j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating cumulative returns is also easy."
      ],
      "metadata": {
        "id": "2jnOT9f-XDad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cumprod() calculates cumulative product\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html\n",
        "df['cum_return'] = ((df['Adj Close'] / df['Adj Close'].shift(1)).cumprod() - 1) * 100\n",
        "df.head()"
      ],
      "metadata": {
        "id": "h1gT593RWlKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot cumulative returns\n",
        "\n",
        "# create figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# line plot\n",
        "ax.plot(df['cum_return'])\n",
        "\n",
        "# set the title\n",
        "ax.set_title('Cumulative Return of SPY (%)')\n",
        "\n",
        "# display plot (optional in the notebook setting)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j1ebnAwsYG0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Cu2r3As9Cq"
      },
      "source": [
        "A **(simple) moving average (MA)** is a widely used indicator in technical analysis that helps smooth out price actions by filtering out the “noise” from random short-term price fluctuations. It is a trend-following, or lagging, indicator because it is based on past prices.\n",
        "\n",
        "Source: https://www.investopedia.com/terms/m/movingaverage.asp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL1KzIJuj2Zm"
      },
      "outputs": [],
      "source": [
        "# rolling() provides rolling window calculation\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html\n",
        "df['ma_50d'] = df['Adj Close'].rolling(window=50).mean()\n",
        "df['ma_100d'] = df['Adj Close'].rolling(window=100).mean()\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P71aIog6FSud"
      },
      "source": [
        "Now, let's plot the adjusted closing price along with the two moving averages we calculated in one plot."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# line plot\n",
        "ax.plot(df['Adj Close'], label=\"Adjusted Closing Price\")\n",
        "ax.plot(df['ma_50d'], label=\"50-day Moving Average\")\n",
        "ax.plot(df['ma_100d'], label=\"100-day Moving Average\")\n",
        "\n",
        "# set the title\n",
        "ax.set_title('Daily Adjusted Closing Price of SPY (USD)')\n",
        "\n",
        "# add legend (based on line labels)\n",
        "ax.legend()\n",
        "\n",
        "# display plot (optional in the notebook setting)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I_p1uR8NciXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deMIJ0-FFcUN"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Calculate weekly volatilities (5-day window) for the SPY series, and plot the result in a line chart.\n",
        "\n",
        "**Volatility** is a statistical measure of the dispersion of returns for a given security or market index. In most cases, the higher the volatility, the riskier the security. Volatility is often measured as either the standard deviation or variance between returns from that same security or market index.\n",
        "\n",
        "Source: https://www.investopedia.com/terms/v/volatility.asp\n",
        "\n",
        "Hint: consider the `.rolling()` and `.std()` methods."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# hint: consider the .rolling() and .std() method.\n"
      ],
      "metadata": {
        "id": "zowI-o_WPEiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzltS25FFwuz"
      },
      "source": [
        "# 4 Linear regression\n",
        "\n",
        "We can build a model to predict future stock prices and see how it performs by comparing it against the actual data. It's often a good idea to start with a simple model as its performance can serve as a benchmark for more complicated models. Thus, we start with a linear regression model. We will predict the next day SPY price with today's price, volume and 50-day moving average.\n",
        "\n",
        "Let's prepare the data for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjSaG6bB5Toq"
      },
      "outputs": [],
      "source": [
        "# create a new column y_price holding next trading day's adjusted closing price\n",
        "df['y_price'] = df['Adj Close'].shift(-1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK5KWFq1u4uL"
      },
      "outputs": [],
      "source": [
        "# create a new dataframe that only contains columns needed for the regression analysis\n",
        "df_reg = df[['Adj Close', 'Volume','ma_50d', 'y_price']].copy()\n",
        "\n",
        "# drop all rows with missing value (mostly due to the 50-day MA column)\n",
        "df_reg.dropna(inplace=True)\n",
        "\n",
        "# let X be today's closing price, volume, 50-day MA\n",
        "X = df_reg[['Adj Close', 'Volume','ma_50d']]\n",
        "\n",
        "# let y be the next day price to predict\n",
        "# that is, we predict price using 1-day lagged information\n",
        "y = df_reg['y_price']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the full dataset into training and test sets. We use the training set to train/fit the model (i.e. to estimate the coefficients of the linear regression model), and the test dataset to evaluate the fitted model's performance.\n",
        "\n",
        "We must respect the time dimension of our time series data when splitting the data into training and test sets. After all, we cannot train on future data/information and predict the price on past data. Therefore, we use the data in 2023 for training and the data in 2024 for testing."
      ],
      "metadata": {
        "id": "w_tpo3kRRjff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use data in 2023 for training\n",
        "X_train = X[X.index < '2024-01-01']\n",
        "y_train = y[y.index < '2024-01-01']\n",
        "\n",
        "# use data in 2024 for testing\n",
        "X_test = X[X.index >= '2024-01-01']\n",
        "y_test = y[y.index >= '2024-01-01']"
      ],
      "metadata": {
        "id": "BgzYMcJnvfwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the [`LinearRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) function in the [sklearn](https://scikit-learn.org/stable/) package for the linear regression task.\n",
        "\n",
        "(There are other options. For example, the scientific computing package [scipy](https://scipy.org/) offers a linear regression function [`linregress()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html). The statistics package [statsmodels](https://www.statsmodels.org/stable/index.html) also supports the [`OLS()`](https://www.statsmodels.org/stable/regression.html) model, Ordinary Least Square model.)\n",
        "\n",
        "After the regression, we evaluate the fitted model on the test set using the MSE (Mean Squared Error) metric. We also plot the true and predicted prices."
      ],
      "metadata": {
        "id": "F0Rt3l_hTDja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM-Y6oMhuecI"
      },
      "outputs": [],
      "source": [
        "# run regression\n",
        "\n",
        "# load the relevant sklearn module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# initialize a regression model\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "lr = LinearRegression()\n",
        "\n",
        "# train/fit on training data\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# predict on test data\n",
        "y_test_pred = lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the `.predict()` method returns a numpy array. [Numpy](https://numpy.org/) is yet another popular Python data science library. It makes operations on arrays/matrices easy to handle."
      ],
      "metadata": {
        "id": "QbtgOysofRZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note the prediction object obtained is a numpy array\n",
        "type(y_test_pred)"
      ],
      "metadata": {
        "id": "FZKcMuIOwejV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note the prediction object obtained is a numpy array\n",
        "y_test_pred"
      ],
      "metadata": {
        "id": "YutrHhJ-0CfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate test MSE (mean squared error)\n",
        "\n",
        "# load the relevant sklearn module\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# calculate the MSE between the true prices in the test data and the predicted prices\n",
        "mse = mean_squared_error(y_test, y_test_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "id": "jZHYaRcg27Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiPqHHxvxaIi"
      },
      "outputs": [],
      "source": [
        "# prepare data for a true vs predicted price plot\n",
        "\n",
        "# create a true vs pred dataframe based on the resulting prediction numpy array and the test data DatetimeIndex\n",
        "df_y_true_vs_pred = pd.DataFrame(y_test_pred, index=y_test.index, columns=[[\"pred\"]])\n",
        "\n",
        "df_y_true_vs_pred[\"true\"] = y_test\n",
        "\n",
        "# however, since we are predicting next day's price, we need to shift(1) to align\n",
        "# the date and the true and predicted value\n",
        "df_y_true_vs_pred = df_y_true_vs_pred.shift(1)\n",
        "df_y_true_vs_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the prediction and true price for comparison\n",
        "\n",
        "# create figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# line plot\n",
        "ax.plot(df_y_true_vs_pred[\"true\"], label=\"True Price\")\n",
        "ax.plot(df_y_true_vs_pred[\"pred\"], label=\"Predicted Price\")\n",
        "\n",
        "# set the title\n",
        "ax.set_title('Regression Analysis: True vs Predicted Price')\n",
        "\n",
        "# add legend (based on line labels)\n",
        "ax.legend()\n",
        "\n",
        "# display plot (optional in the notebook setting)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0hyUQDJxNsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Can you improve the test MSE by modifying the linear regression model, for example, adding new X variables?"
      ],
      "metadata": {
        "id": "LVEQuz1cA76c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n"
      ],
      "metadata": {
        "id": "T9lvhMeCBbWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix\n",
        "\n",
        "We can also perform the linear regression analysis using the statistics package [statsmodels](https://www.statsmodels.org/stable/index.html). The package supports the [`OLS()`](https://www.statsmodels.org/stable/regression.html) model (Ordinary Least Square model is just another name for linear regression). It also offers an easy way to write [regression formula](https://www.statsmodels.org/dev/example_formulas.html), and produces a nice regression report. This regression report is especially useful for causal analysis, where you care about statistical inference in the regression (e.g., confidence intervals or hypothesis tests for the estimated coefficients).\n",
        "\n"
      ],
      "metadata": {
        "id": "wt_lbTRF3iLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# only use 2023 data for training\n",
        "df_reg_train = df_reg.loc[df_reg.index < '2024-01-01']\n",
        "\n",
        "# create an OLS model\n",
        "# note the formula; because the column name 'Adj Close' contains a space, we need to wrap it in a Q() function\n",
        "ols_model = smf.ols(formula=\"y_price ~ Q('Adj Close') + Volume + ma_50d\", data=df_reg_train)\n",
        "\n",
        "# fit the OLS model\n",
        "result = ols_model.fit()\n",
        "\n",
        "# print the regression report\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "oCFPcAKo0jsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NK0L7QnAA3PS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}